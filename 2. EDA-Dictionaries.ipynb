{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing and Predicting Player Count Trends in Online Games\n",
    "\n",
    "## Part 2: Exploratory Data Analysis\n",
    "\n",
    "Now that we have dataframes that will be easier to analyze and work with, we can complete some EDA. We will be posing different queries and attempt to answer them with constructed visualizations. These queries are:\n",
    "\n",
    "1. What game had the largest change in players over a defined period (week, month, year)?\n",
    "2. Of all our dataframes, when is the single largest daily change in player base?\n",
    "3. Is there a similar trend in the change in players across all games? If not, what does this suggest?\n",
    "4. How does a larger player base impact volitility in number of players? \n",
    "5. How are number of players and viewers distributed?\n",
    "6. How does an event affect number of players?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fsds v0.2.30 loaded.  Read the docs: https://fs-ds.readthedocs.io/en/latest/ \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_86794f0a_60d1_11eb_9a9a_144f8ac5640c\" ><caption>Loaded Packages and Handles</caption><thead>    <tr>        <th class=\"col_heading level0 col0\" >Handle</th>        <th class=\"col_heading level0 col1\" >Package</th>        <th class=\"col_heading level0 col2\" >Description</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                                <td id=\"T_86794f0a_60d1_11eb_9a9a_144f8ac5640crow0_col0\" class=\"data row0 col0\" >dp</td>\n",
       "                        <td id=\"T_86794f0a_60d1_11eb_9a9a_144f8ac5640crow0_col1\" class=\"data row0 col1\" >IPython.display</td>\n",
       "                        <td id=\"T_86794f0a_60d1_11eb_9a9a_144f8ac5640crow0_col2\" class=\"data row0 col2\" >Display modules with helpful display and clearing commands.</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_86794f0a_60d1_11eb_9a9a_144f8ac5640crow1_col0\" class=\"data row1 col0\" >fs</td>\n",
       "                        <td id=\"T_86794f0a_60d1_11eb_9a9a_144f8ac5640crow1_col1\" class=\"data row1 col1\" >fsds</td>\n",
       "                        <td id=\"T_86794f0a_60d1_11eb_9a9a_144f8ac5640crow1_col2\" class=\"data row1 col2\" >Custom data science bootcamp student package</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_86794f0a_60d1_11eb_9a9a_144f8ac5640crow2_col0\" class=\"data row2 col0\" >mpl</td>\n",
       "                        <td id=\"T_86794f0a_60d1_11eb_9a9a_144f8ac5640crow2_col1\" class=\"data row2 col1\" >matplotlib</td>\n",
       "                        <td id=\"T_86794f0a_60d1_11eb_9a9a_144f8ac5640crow2_col2\" class=\"data row2 col2\" >Matplotlib's base OOP module with formatting artists</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_86794f0a_60d1_11eb_9a9a_144f8ac5640crow3_col0\" class=\"data row3 col0\" >plt</td>\n",
       "                        <td id=\"T_86794f0a_60d1_11eb_9a9a_144f8ac5640crow3_col1\" class=\"data row3 col1\" >matplotlib.pyplot</td>\n",
       "                        <td id=\"T_86794f0a_60d1_11eb_9a9a_144f8ac5640crow3_col2\" class=\"data row3 col2\" >Matplotlib's matlab-like plotting module</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_86794f0a_60d1_11eb_9a9a_144f8ac5640crow4_col0\" class=\"data row4 col0\" >np</td>\n",
       "                        <td id=\"T_86794f0a_60d1_11eb_9a9a_144f8ac5640crow4_col1\" class=\"data row4 col1\" >numpy</td>\n",
       "                        <td id=\"T_86794f0a_60d1_11eb_9a9a_144f8ac5640crow4_col2\" class=\"data row4 col2\" >scientific computing with Python</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_86794f0a_60d1_11eb_9a9a_144f8ac5640crow5_col0\" class=\"data row5 col0\" >pd</td>\n",
       "                        <td id=\"T_86794f0a_60d1_11eb_9a9a_144f8ac5640crow5_col1\" class=\"data row5 col1\" >pandas</td>\n",
       "                        <td id=\"T_86794f0a_60d1_11eb_9a9a_144f8ac5640crow5_col2\" class=\"data row5 col2\" >High performance data structures and tools</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_86794f0a_60d1_11eb_9a9a_144f8ac5640crow6_col0\" class=\"data row6 col0\" >sns</td>\n",
       "                        <td id=\"T_86794f0a_60d1_11eb_9a9a_144f8ac5640crow6_col1\" class=\"data row6 col1\" >seaborn</td>\n",
       "                        <td id=\"T_86794f0a_60d1_11eb_9a9a_144f8ac5640crow6_col2\" class=\"data row6 col2\" >High-level data visualization library based on matplotlib</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2184efcba58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] Pandas .iplot() method activated.\n"
     ]
    }
   ],
   "source": [
    "# we import necessary libraries\n",
    "\n",
    "!pip install -U fsds\n",
    "\n",
    "import statistics as stats\n",
    "from fsds.imports import * \n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Missing column provided to 'parse_dates': 'time'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-d6118098551e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# we import our dataframes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mcsgo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/Clean/csgo.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparse_dates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'time'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_col\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mdota\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/Clean/dota.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mrl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/Clean/rl.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\envs\\learn-env\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    684\u001b[0m     )\n\u001b[0;32m    685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\envs\\learn-env\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 452\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\envs\\learn-env\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    945\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 946\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    947\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    948\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\envs\\learn-env\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1176\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1177\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1178\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1179\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1180\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\envs\\learn-env\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   2064\u001b[0m                 \u001b[0m_validate_usecols_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2065\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2066\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_parse_dates_presence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2067\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_noconvert_columns\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2068\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\envs\\learn-env\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_validate_parse_dates_presence\u001b[1;34m(self, columns)\u001b[0m\n\u001b[0;32m   1542\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmissing_cols\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1543\u001b[0m             raise ValueError(\n\u001b[1;32m-> 1544\u001b[1;33m                 \u001b[1;34mf\"Missing column provided to 'parse_dates': '{missing_cols}'\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1545\u001b[0m             )\n\u001b[0;32m   1546\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Missing column provided to 'parse_dates': 'time'"
     ]
    }
   ],
   "source": [
    "# we import our dataframes\n",
    "\n",
    "csgo = pd.read_csv('data/Clean/csgo.csv', parse_dates = ['DateTime'], index_col = 0)\n",
    "dota = pd.read_csv('data/Clean/dota.csv')\n",
    "rl = pd.read_csv('data/Clean/rl.csv')\n",
    "tf = pd.read_csv('data/Clean/tf.csv')\n",
    "\n",
    "ls = [csgo, dota, rl, tf]\n",
    "\n",
    "ls = list(map(lambda df: df.drop(columns = \"Unnamed: 0\"), ls))\n",
    "\n",
    "#ls[0].info()\n",
    "\n",
    "\n",
    "\n",
    "# our time column did not import as a datetime object, so we have to complete this again. \n",
    "\n",
    "for df in ls:\n",
    "    \n",
    "    for i in range(len(df['time'])):\n",
    "        t = df['time'][i]\n",
    "        \n",
    "        df['time'][i] = str(t).replace('-', '')\n",
    "        \n",
    "    df['time'] = pd.to_datetime(df['time'], format = '%Y%m%d')\n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dota"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Which games had the largest change in players over a week, month, and year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we currently have daily percent changes, so we will have to calculate rolling averages for the \n",
    "# time periods above.\n",
    "\n",
    "times = ['W', 'M', 'Y']\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(ncols = 3, nrows = 4, figsize = (15, 10))\n",
    "\n",
    "for i, df in enumerate(ls):\n",
    "    for x, t  in enumerate(times):\n",
    "        df_plot = df.groupby(pd.Grouper(key = 'time', freq = t)).mean()\n",
    "        ax = sns.scatterplot(data = df_plot, x = 'time', y = '%chg_players', ax = axes[i][x])\n",
    "        ax.axhline(0, ls = '--')\n",
    "        #ax.set(title = 'Average change in players by ' + t, xlabel = 'Time', ylim = (-0.5, 0.5))\n",
    "        \n",
    "game_labels = ['CS:GO', 'DOTA 2', 'Rocket League', 'Team Fortress 2']\n",
    "time_labels = ['Week', 'Month', 'Year']\n",
    "\n",
    "for i, game in enumerate(game_labels):\n",
    "    axes[i][0].set_ylabel(game, fontsize = 35, rotation = 0, labelpad = 200)\n",
    "    axes[i][1].set(ylabel = '')\n",
    "    axes[i][2].set(ylabel = '')\n",
    "    \n",
    "    \n",
    "for i, time in enumerate(time_labels):\n",
    "    axes[0][i].set_title('Percent Change by '+time, fontsize = 35)\n",
    "    axes[1][i].set(title = '')\n",
    "    axes[2][i].set(title = '')\n",
    "    axes[3][i].set(title = '')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expanding those graphs that have outliers, suggesting that these are our maximums. These graphs are [0,0], [0, 1], and \n",
    "# [0, 2] which are all 'csgo'. Why does this game have such random growth compared to other games?\n",
    "\n",
    "fig, axes = plt.subplots(ncols = 1, nrows = 3, figsize = (10, 25))\n",
    "\n",
    "df = ls[0]\n",
    "\n",
    "for x, t in enumerate(times):\n",
    "    df_plot = df.groupby(pd.Grouper(key = 'time', freq = t)).mean()\n",
    "    ax = sns.scatterplot(data = df_plot, x = 'time', y = '%chg_players', ax = axes[x])\n",
    "    ax.set(title = 'Change in Players by ' + t + ' for CS:GO', xlabel = 'Time', ylabel = 'Change in Players')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From our above visualizations, it appears that CSGO had the single largest change in player base halfway through 2012.\n",
    "\n",
    "### 2. Of all our dataframes, when is the single largest daily change in player base?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will have to find the maximum change in both the positive and negative direction for each of our dataframes\n",
    "\n",
    "maxes = list(map(lambda df: df['%chg_players'].max(), ls))\n",
    "mins = list(map(lambda df: df['%chg_players'].min(), ls))\n",
    "\n",
    "# this worked for our maximums, but our mins represent times at which these games were not available to players,\n",
    "# so negative change is at -1.0 or -100%. Instead, we will filter out the instances where negative change is -1, letting us\n",
    "# capture those times where the game was still active, but change in players was still at a negative maximum.\n",
    "\n",
    "# we update the lambda function to filter out change of -1.0\n",
    "\n",
    "mins = list(map(lambda df: df['%chg_players'].where(df['%chg_players'] != -1.0).min(), ls))\n",
    "\n",
    "print(maxes, mins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This still suggests that CS:GO has the largest change of all our games. What is is about CS:GO that prescribes such volatility? Let's hone in on these days where the change was so great. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_max_min = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_max_min = ls[0].where(ls[0]['%chg_players'] == maxes[0])\n",
    "df_max_min = df_max_min.append(ls[0].where(ls[0]['%chg_players'] == mins[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_max_min.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that this represents an enormous spike in players on 8-01-2012, but that of this spike only 3% were retained. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizing the time period above, 30 days before and after. \n",
    "\n",
    "df_plot = ls[0].where(ls[0]['time'] > \"2015-01-13\")\n",
    "df_plot = df_plot.where(df_plot['time'] < \"2015-06-10\")\n",
    "\n",
    "\n",
    "plot = sns.lineplot(data = df_plot, y = 'players', x = 'time')\n",
    "plot.set(title = 'Daily % Change for CS:GO')\n",
    "plot.set_ylabel('Player Count', rotation = 0, labelpad = 45)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The spike in player count above is due to the release of CS:GO. This tells us that of all games we have data on, CS:GO had the most successful release, if player count is the primary measure of success. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Is there a similar trend in the change in players across all games? If not, what does this suggest?\n",
    "\n",
    "We will compare the changes in player counts that can be attributed to trends, such as more players being online during a weekend, or a particular time of year. We can find the correlation between players or % change in players."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# we can construct a correlation matrix from a joining of all our dataframes.\n",
    "# we must be careful with the labels of our columns, adding suffixes to all.\n",
    "\n",
    "csgo = ls[0]\n",
    "\n",
    "#for col in csgo.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sns.lineplot(data = ls[0], x = ls[0]['time'], y = 'players').set(xlim = (\"2018-01-01\",\"2018-01-08\"), ylim = (500000, 700000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in ls:\n",
    "    \n",
    "    w = sns.lineplot(data = df, x ='time', y = '%chg_players').set(xlim = (\"2018-01-01\",\"2018-01-08\"), ylim = (-0.2, 0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in ls:\n",
    "    \n",
    "    m = sns.lineplot(data = df, x ='time', y = '%chg_players').set(xlim = (\"2018-01-01\",\"2018-02-01\"), ylim = (-.5, .5))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in ls:\n",
    "    \n",
    "    df_plot = df.groupby(pd.Grouper(key = 'time', freq = 'W')).mean()\n",
    "    y = sns.lineplot(data = df_plot, x ='time', y = '%chg_players').set(xlim = (\"2018-01-01\",\"2019-01-01\"), ylim = (-.2, .2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. How does a larger player base impact volitility in number of players? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will be plotting number of players versus a statistical measure of volatility\n",
    "# volatility is the square root of variance, so let us calculate weekly volatility and plot\n",
    "# this versus number of players.\n",
    "\n",
    "df = ls[0]\n",
    "\n",
    "variances = []\n",
    "week = []\n",
    "\n",
    "for i in df['players']:\n",
    "    \n",
    "    week.append(i)\n",
    "    \n",
    "    if len(week) == 7:\n",
    "        \n",
    "        variances.append(stats.variance(week))\n",
    "        week = []\n",
    "        \n",
    "if len(week) > 0:\n",
    "    \n",
    "    variances.append(stats.variance(week))\n",
    "    \n",
    "\n",
    "volatilities = []\n",
    "\n",
    "for v in variances:\n",
    "    \n",
    "    # volatility is equal to sq_root of variance times sq_root of time period in question (one week)\n",
    "    \n",
    "    volatility = (v**0.5)*(7**0.5)\n",
    "    volatilities.append(volatility)\n",
    "    \n",
    "len(volatilities)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = df.set_index('time')\n",
    "\n",
    "\n",
    "df_plot.groupby(pd.Grouper(freq = 'W')).var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we group our dataframe weekly by average player count\n",
    "\n",
    "df_plot = df.groupby(pd.Grouper(key = 'time', freq = 'W')).mean()\n",
    "len(df_plot)\n",
    "\n",
    "sns.regplot(x = df_plot['players'], y = volatilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# might this vary by game?\n",
    "\n",
    "fig, axes = plt.subplots(ncols = 1, nrows = 4, figsize = (8, 25))\n",
    "\n",
    "for x, df in enumerate(ls):\n",
    "    variances = []\n",
    "    week = []\n",
    "\n",
    "    for i in df['players']:\n",
    "    \n",
    "        week.append(i)\n",
    "    \n",
    "        if len(week) == 7:\n",
    "        \n",
    "            variances.append(stats.variance(week))\n",
    "            week = []\n",
    "        \n",
    "    if len(week) > 1:\n",
    "    \n",
    "        variances.append(stats.variance(week))\n",
    "    elif len(week) == 1:\n",
    "        variances.append(0)\n",
    "    \n",
    "\n",
    "    volatilities = []\n",
    "\n",
    "    for v in variances:\n",
    "    \n",
    "        # volatility is equal to sq_root of variance times sq_root of time period in question (one week)\n",
    "    \n",
    "        volatility = (v**0.5)*(7**0.5)\n",
    "        volatilities.append(volatility)\n",
    "        \n",
    "    df_plot = df.groupby(pd.Grouper(key = 'time', freq = 'W')).mean()\n",
    "    len(df_plot)\n",
    "\n",
    "    ax = sns.regplot(x = df_plot['players']/1000, y = volatilities, ax = axes[x])\n",
    "    ax.set_ylabel('Volatility')\n",
    "    ax.set(title = \"Volatility V. Player Count for \" + game_labels[x], xlabel = \"Player Count (Thousands)\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. How are number of players and number of viewers distributed among our games?\n",
    "We expect players to be normally distributed, while viewers may have a less normal distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in ls:\n",
    "    sns.displot(df['players'], kde = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in ls:\n",
    "    sns.displot(df['viewers'], kde = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. How does an event affect number of players?\n",
    "We will compare average number of players during an event versus other times. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a violin plot would compare counts during vs outside of events. \n",
    "\n",
    "fig, axes = plt.subplots(ncols = 1, nrows = 3, figsize = (10, 20))\n",
    "\n",
    "for n, df in enumerate(ls[0:3]):\n",
    "    \n",
    "    df['all'] = ''\n",
    "    \n",
    "    ax = sns.violinplot(x = 'all', y=\"players\", hue=df[\"event\"],\n",
    "                    data=df, palette=\"muted\", split=True, ax = axes[n])\n",
    "    \n",
    "# this code is unable to violin plot Team Fortress 2 because this game does not have\n",
    "# events, as detailed in our introduction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and how does event affect viewers? Expected more than players\n",
    "\n",
    "fig, axes = plt.subplots(ncols = 1, nrows = 3, figsize = (10, 20))\n",
    "\n",
    "for n, df in enumerate(ls[0:3]):\n",
    "    \n",
    "    df['all'] = ''\n",
    "    \n",
    "    ax = sns.violinplot(x = 'all', y=\"viewers\", hue=df[\"event\"],\n",
    "                    data=df, palette=\"muted\", split=True, ax = axes[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
